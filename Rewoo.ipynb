{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFpkqWw48IEPoRE2AGPHVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bilal-Ahmad-5/Planning-Agent/blob/main/Rewoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iDnQxgNi99A",
        "outputId": "d2a5fbce-b328-440e-a100-bf3941389234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/131.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet --upgrade langgraph langchain_experimental langchain langchain_community langchain-google-genai langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily_api_key')\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Gemini_Api_Key')\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchai_api_key')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Rewoo-agent\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ],
      "metadata": {
        "id": "lY8Dh3f7jDm-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "tools=TavilySearchResults(max_results=1)\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-8b\")"
      ],
      "metadata": {
        "id": "g5ccy_w0jAyv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class ReWOO(TypedDict):\n",
        "    task: str\n",
        "    plan_string: str\n",
        "    steps: List\n",
        "    results: dict\n",
        "    result: str"
      ],
      "metadata": {
        "id": "M_ZQIo1ojZO8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"For the following task, make plans that can solve the problem step by step. For each plan, indicate \\\n",
        "which external tool together with tool input to retrieve evidence. You can store the evidence into a \\\n",
        "variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n",
        "\n",
        "Tools can be one of the following:\n",
        "(1) Google[input]: Worker that searches results from Google. Useful when you need to find short\n",
        "and succinct answers about a specific topic. The input should be a search query.\n",
        "(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general\n",
        "world knowledge and common sense. Prioritize it when you are confident in solving the problem\n",
        "yourself. Input can be any instruction.\n",
        "\n",
        "For example,\n",
        "Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\n",
        "hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\n",
        "less than Toby. How many hours did Rebecca work?\n",
        "Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\n",
        "with Wolfram Alpha. #E1 = WolframAlpha[Solve x + (2x − 10) + ((2x − 10) − 8) = 157]\n",
        "Plan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\n",
        "Plan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2 ∗ #E2 − 10) − 8]\n",
        "\n",
        "Begin!\n",
        "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
        "\n",
        "Task: {task}\"\"\"\n",
        "task = \"what is the exact hometown of the 2024 mens australian open winner\"\n",
        "result = model.invoke(prompt.format(task=task))\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-RbSGS3jgwn",
        "outputId": "28250c53-29c4-4c2c-b969-052399f1b8f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan: First, identify the winner of the 2024 men's Australian Open.  This requires finding the winner's name and verifying the year is correct.\n",
            "\n",
            "#E1 = Google[2024 men's Australian Open winner]\n",
            "\n",
            "Plan: Once the winner's name is known, use a search engine to find their hometown.\n",
            "\n",
            "#E2 = Google[hometown of {winner's name}]  \n",
            "     \n",
            "     (Note:  \"{winner's name}\" will be replaced with the actual name retrieved in #E1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Regex to match expressions of the form E#... = ...[...]\n",
        "regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
        "prompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\n",
        "planner = prompt_template | model\n",
        "\n",
        "\n",
        "def get_plan(state: ReWOO):\n",
        "    task = state[\"task\"]\n",
        "    result = planner.invoke({\"task\": task})\n",
        "    # Find all matches in the sample text\n",
        "    matches = re.findall(regex_pattern, result.content)\n",
        "    return {\"steps\": matches, \"plan_string\": result.content}"
      ],
      "metadata": {
        "id": "ne6cVfoEk2-r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_current_task(state: ReWOO):\n",
        "    if \"results\" not in state or state[\"results\"] is None:\n",
        "        return 1\n",
        "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
        "        return None\n",
        "    else:\n",
        "        return len(state[\"results\"]) + 1\n",
        "\n",
        "\n",
        "def tool_execution(state: ReWOO):\n",
        "    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n",
        "    _step = _get_current_task(state)\n",
        "    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n",
        "    _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
        "    for k, v in _results.items():\n",
        "        tool_input = tool_input.replace(k, v)\n",
        "    if tool == \"Google\":\n",
        "        result = tools.invoke(tool_input)\n",
        "    elif tool == \"LLM\":\n",
        "        result = model.invoke(tool_input)\n",
        "    else:\n",
        "        raise ValueError\n",
        "    _results[step_name] = str(result)\n",
        "    return {\"results\": _results}"
      ],
      "metadata": {
        "id": "m8bFJwCQmSlg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solve_prompt = \"\"\"Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \\\n",
        "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\n",
        "contain irrelevant information.\n",
        "\n",
        "{plan}\n",
        "\n",
        "Now solve the question or task according to provided Evidence above. Respond with the answer\n",
        "directly with no extra words.\n",
        "\n",
        "Task: {task}\n",
        "Response:\"\"\"\n",
        "\n",
        "\n",
        "def solve(state: ReWOO):\n",
        "    plan = \"\"\n",
        "    for _plan, step_name, tool, tool_input in state[\"steps\"]:\n",
        "        _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
        "        for k, v in _results.items():\n",
        "            tool_input = tool_input.replace(k, v)\n",
        "            step_name = step_name.replace(k, v)\n",
        "        plan += f\"Plan: {_plan}\\n{step_name} = {tool}[{tool_input}]\"\n",
        "    prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n",
        "    result = model.invoke(prompt)\n",
        "    return {\"result\": result.content}"
      ],
      "metadata": {
        "id": "4kAr8qg0majF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _route(state):\n",
        "    _step = _get_current_task(state)\n",
        "    if _step is None:\n",
        "        # We have executed all tasks\n",
        "        return \"solve\"\n",
        "    else:\n",
        "        # We are still executing tasks, loop back to the \"tool\" node\n",
        "        return \"tool\""
      ],
      "metadata": {
        "id": "F4Rb1nxImXBV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "graph = StateGraph(ReWOO)\n",
        "graph.add_node(\"plan\", get_plan)\n",
        "graph.add_node(\"tool\", tool_execution)\n",
        "graph.add_node(\"solve\", solve)\n",
        "graph.add_edge(\"plan\", \"tool\")\n",
        "graph.add_edge(\"solve\", END)\n",
        "graph.add_conditional_edges(\"tool\", _route)\n",
        "graph.add_edge(START, \"plan\")\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "e_ZSp3TXmeGd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in app.stream({\"task\": task}):\n",
        "    print(s)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLQ6mw7lmgMU",
        "outputId": "a86521eb-6a27-4f80-dd91-22427ed20e01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'plan': {'steps': [(\"First, identify the 2024 men's Australian Open winner.  This information is readily available through reliable sports news sources.\", '#E1', 'Google', '\"2024 Australian Open men\\'s winner\"'), ('Once the winner is identified, use the retrieved information to determine their hometown.', '#E2', 'Google', '\"hometown of [winner\\'s name')], 'plan_string': 'Plan: First, identify the 2024 men\\'s Australian Open winner.  This information is readily available through reliable sports news sources.\\n\\n#E1 = Google[\"2024 Australian Open men\\'s winner\"]\\n\\nPlan: Once the winner is identified, use the retrieved information to determine their hometown.\\n\\n#E2 = Google[\"hometown of [winner\\'s name]\"]'}}\n",
            "---\n",
            "{'tool': {'results': {'#E1': '[{\\'title\\': \"Australian Open 2024 Winners: Men\\'s, Women\\'s, Check ...\", \\'url\\': \\'https://www.jagranjosh.com/general-knowledge/australian-open-winners-2024-1708691191-1\\', \\'content\\': \"ALSO READ| List of Australian Open Winners List - Men’s Single Title Champions Rohan Bopanna and Matthew Ebden secured the men\\'s doubles tennis title at the 2024 Australian Open by triumphing over Simone Bolelli and Andrea Vavassori in the final, clinching victory with a score of 7–6(7–0), 7–5. Hsieh Su-wei and Elise Mertens clinched the women\\'s doubles tennis title at the 2024 Australian Open by defeating Lyudmyla Kichenok and Jeļena Ostapenko in the final with a score of 6–1, 7–5. Hsieh Su-wei and Jan Zieliński secured the mixed doubles tennis title at the 2024 Australian Open after overcoming Desirae Krawczyk and Neal Skupski in a thrilling final, prevailing with a score of 6–7(5–7), 6–4, [11–9].\", \\'score\\': 0.92857105}]'}}}\n",
            "---\n",
            "{'tool': {'results': {'#E1': '[{\\'title\\': \"Australian Open 2024 Winners: Men\\'s, Women\\'s, Check ...\", \\'url\\': \\'https://www.jagranjosh.com/general-knowledge/australian-open-winners-2024-1708691191-1\\', \\'content\\': \"ALSO READ| List of Australian Open Winners List - Men’s Single Title Champions Rohan Bopanna and Matthew Ebden secured the men\\'s doubles tennis title at the 2024 Australian Open by triumphing over Simone Bolelli and Andrea Vavassori in the final, clinching victory with a score of 7–6(7–0), 7–5. Hsieh Su-wei and Elise Mertens clinched the women\\'s doubles tennis title at the 2024 Australian Open by defeating Lyudmyla Kichenok and Jeļena Ostapenko in the final with a score of 6–1, 7–5. Hsieh Su-wei and Jan Zieliński secured the mixed doubles tennis title at the 2024 Australian Open after overcoming Desirae Krawczyk and Neal Skupski in a thrilling final, prevailing with a score of 6–7(5–7), 6–4, [11–9].\", \\'score\\': 0.92857105}]', '#E2': \"[{'title': 'Winner History, Family Crest & Coats of Arms', 'url': 'https://www.houseofnames.com/winner-family-crest/german', 'content': 'The surname Winner was first found in Germany, where the name Winner came from humble beginnings but gained a significant reputation for its contribution to the', 'score': 0.36697587}]\"}}}\n",
            "---\n",
            "{'solve': {'result': 'Unable to determine.'}}\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}